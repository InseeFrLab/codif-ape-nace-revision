apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: run-relabel-naf08-to-naf25
spec:
  serviceAccountName: workflow
  volumes:
    - name: dshm
      emptyDir:
        medium: Memory
        sizeLimit: 64Gi
  entrypoint: main
  arguments:
    parameters:
      - name: params-conf-list
        value: '[
              {"LLM_NAME": "mistralai/Ministral-8B-Instruct-2410", "THIRD": 1},
              {"LLM_NAME": "mistralai/Ministral-8B-Instruct-2410", "THIRD": 2},
              {"LLM_NAME": "mistralai/Ministral-8B-Instruct-2410", "THIRD": 3}
            ]'

  templates:
    - name: main
      dag:
        tasks:
          - name: relabel-naf08-to-naf25
            template: run-relabel
            arguments:
              parameters:
                - name: LLM_NAME
                  value: '{{item.LLM_NAME}}'
                - name: THIRD
                  value: '{{item.THIRD}}'
            withParam: '{{workflow.parameters.params-conf-list}}'
    - name: run-relabel
      inputs:
        parameters:
          - name: LLM_NAME
          - name: THIRD
      nodeSelector:
        nvidia.com/gpu.product: "NVIDIA-H100-PCIe"
      container:
        image: inseefrlab/onyxia-vscode-pytorch:py3.12.6-gpu
        imagePullPolicy: Always
        resources:
          limits:
            nvidia.com/gpu: 1
        command: ["/bin/bash", -c]
        args:
          - |
            git clone https://github.com/InseeFrLab/codif-ape-nace-revision.git
            cd codif-ape-nace-revision/
            pip install -r requirements.txt

            if [ "{{inputs.parameters.LLM_NAME}}" == "Qwen/Qwen2.5-72B-Instruct-GPTQ-Int4" ] || [ "{{inputs.parameters.LLM_NAME}}" == "hugging-quants/Meta-Llama-3.1-70B-Instruct-GPTQ-INT4" ]; then
              cd ..
              git clone https://github.com/AutoGPTQ/AutoGPTQ
              cd AutoGPTQ
              pip install -e .
              cd ../codif-ape-nace-revision/
            fi

            export MC_HOST_s3=https://$AWS_ACCESS_KEY_ID:$AWS_SECRET_ACCESS_KEY@$AWS_S3_ENDPOINT
            huggingface-cli login --token $HF_TOKEN
            python encode-multivoque.py --experiment_name NACE2025 --llm_name {{inputs.parameters.LLM_NAME}} --third {{inputs.parameters.THIRD}}
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
        env:
          # env var for s3 connexion
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: my-s3-creds
                key: accessKey
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: my-s3-creds
                key: secretKey
          - name: AWS_DEFAULT_REGION
            value: us-east-1
          - name: AWS_S3_ENDPOINT
            value: minio.lab.sspcloud.fr
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token
                key: token
          - name: MLFLOW_S3_ENDPOINT_URL
            value: https://minio.lab.sspcloud.fr
          - name: MLFLOW_TRACKING_URI
            value: https://projet-ape-mlflow.user.lab.sspcloud.fr/
